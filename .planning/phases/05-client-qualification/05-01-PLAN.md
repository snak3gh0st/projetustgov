---
phase: 05-client-qualification
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/loader/db_models.py
  - src/loader/upsert.py
  - src/parser/schemas.py
  - src/orchestrator/pipeline.py
autonomous: true

must_haves:
  truths:
    - "Proponentes table exists in PostgreSQL with CNPJ as unique natural key"
    - "ETL pipeline extracts unique proponentes from propostas CSV and upserts to proponentes table"
    - "Each proponente has is_osc flag computed from natureza_juridica codes"
    - "Aggregated metrics (total_propostas, total_emendas, valor_total_emendas) are computed per proponente"
    - "Re-running pipeline does not duplicate proponentes (idempotent via CNPJ)"
  artifacts:
    - path: "src/loader/db_models.py"
      provides: "Proponente SQLAlchemy model"
      contains: "class Proponente"
    - path: "src/loader/upsert.py"
      provides: "Proponente upsert and aggregation logic"
      contains: "proponentes"
    - path: "src/orchestrator/pipeline.py"
      provides: "Proponente extraction integrated into pipeline"
      contains: "proponentes"
  key_links:
    - from: "src/orchestrator/pipeline.py"
      to: "src/loader/upsert.py"
      via: "load_extraction_data includes proponentes"
      pattern: "proponentes"
    - from: "src/parser/schemas.py"
      to: "src/loader/db_models.py"
      via: "Column mapping extracts proponente fields from propostas CSV"
      pattern: "IDENTIF_PROPONENTE|identif_proponente"
---

<objective>
Add Proponente dimension table to the database and integrate proponente extraction into the ETL pipeline. Proponentes are extracted from the propostas CSV (deduplicated by CNPJ), classified as OSC or government using IBGE CONCLA natureza_juridica codes, and stored with pre-computed aggregation metrics.

Purpose: Foundation for client qualification - enables ranking proponents by value (fewer projects = higher value, OSC vs prefeitura filtering).
Output: Proponente model, ETL extraction logic, aggregation queries, pipeline integration.
</objective>

<execution_context>
@/Users/pauloloureiro/.claude/get-shit-done/workflows/execute-plan.md
@/Users/pauloloureiro/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-client-qualification/05-RESEARCH.md
@src/loader/db_models.py
@src/loader/upsert.py
@src/parser/schemas.py
@src/orchestrator/pipeline.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add Proponente model and update schemas</name>
  <files>src/loader/db_models.py, src/parser/schemas.py</files>
  <action>
1. Add `Proponente` model to `src/loader/db_models.py` following existing patterns (Mapped, Optional, audit columns):
   - `id` (PK, autoincrement)
   - `cnpj` (String(14), unique=True, index=True, nullable=False) - natural key, stored as 14-digit zero-padded string
   - `nome` (Optional[str])
   - `natureza_juridica` (Optional[str], String(5), index=True) - IBGE CONCLA code e.g. "103-1"
   - `estado` (Optional[str], String(2))
   - `municipio` (Optional[str])
   - `cep` (Optional[str], String(8))
   - `endereco` (Optional[str])
   - `bairro` (Optional[str])
   - `is_osc` (bool, default=False, index=True) - computed from natureza_juridica
   - `total_propostas` (int, default=0)
   - `total_emendas` (int, default=0)
   - `valor_total_emendas` (Optional[float], Float)
   - `created_at`, `updated_at`, `extraction_date` - same pattern as other models

2. Add `proponente_cnpj` column to existing `Proposta` model:
   - `proponente_cnpj: Mapped[Optional[str]] = mapped_column(String(14), index=True)`
   - Comment: "Extracted from IDENTIF_PROPONENTE, links to proponentes.cnpj"

3. Update `src/parser/schemas.py`:
   - Add to `COLUMN_ALIASES["propostas"]` new mappings:
     - `"proponente_cnpj": ["identif_proponente"]`
     - `"natureza_juridica_proponente": ["natureza_juridica"]` (NOTE: this is the proponente's natureza juridica, NOT programa's)
     - `"cep_proponente": ["cep_proponente"]`
     - `"endereco_proponente": ["endereco_proponente"]`
     - `"bairro_proponente": ["bairro_proponente"]`
   - These columns are NOT in EXPECTED_COLUMNS (they're extracted for proponente dimension, not stored on propostas table directly)
  </action>
  <verify>
Run `python -c "from src.loader.db_models import Proponente, Proposta; print('Proponente model OK'); print('proponente_cnpj' in [c.name for c in Proposta.__table__.columns])"` - should print True.
  </verify>
  <done>Proponente model exists with CNPJ as unique key, is_osc flag, aggregation columns. Proposta has proponente_cnpj column. Schema aliases map CSV columns.</done>
</task>

<task type="auto">
  <name>Task 2: Integrate proponente extraction into ETL pipeline</name>
  <files>src/loader/upsert.py, src/orchestrator/pipeline.py</files>
  <action>
1. In `src/loader/upsert.py`:
   - Import `Proponente` from db_models
   - Add proponente extraction function `extract_proponentes_from_propostas(propostas_records: list[dict], raw_df: pl.DataFrame) -> list[dict]`:
     - Takes validated proposta records AND the raw propostas DataFrame (needed for extra columns like IDENTIF_PROPONENTE, NATUREZA_JURIDICA, CEP, etc.)
     - For each unique CNPJ (from `identif_proponente` column in raw_df):
       - Normalize CNPJ: strip non-digits, zero-pad to 14 chars
       - Skip if CNPJ is empty or all zeros
       - Extract: nome (from `nm_proponente`), natureza_juridica, estado (`uf_proponente`), municipio (`munic_proponente`), cep (`cep_proponente`), endereco (`endereco_proponente`), bairro (`bairro_proponente`)
       - Compute `is_osc`: True if natureza_juridica starts with "3" (3XX range = non-profits), False if starts with "1" (government), False otherwise
       - Count total_propostas for this CNPJ from the raw_df
     - Return list of proponente dicts ready for upsert
   - Add proponente aggregation function `compute_proponente_aggregations(session: Session) -> None`:
     - Query propostas table grouped by proponente_cnpj to count total_propostas
     - Query emendas via junction tables to count total_emendas and sum valor_total_emendas per proponente CNPJ
     - Update proponentes table with computed values
   - Update `load_extraction_data()`:
     - Add "proponentes" to the loading sequence BEFORE propostas (proponentes is a dimension table)
     - After loading all entities, call `compute_proponente_aggregations(session)` to update aggregated metrics

2. In `src/orchestrator/pipeline.py`:
   - After parsing the propostas file, extract proponentes from the raw DataFrame:
     - Call `extract_proponentes_from_propostas()` with both validated records and raw df
     - Store result in `validated_data["proponentes"]`
   - After propostas validation, also extract `proponente_cnpj` for each proposta record:
     - Look up IDENTIF_PROPONENTE from raw df, normalize to 14-digit CNPJ
     - Add to each proposta dict as `proponente_cnpj`
   - Add `"proponentes": []` to the initial validated_data dict

OSC classification logic (per RESEARCH.md IBGE CONCLA):
```python
OSC_CODES = {'306-9', '307-7', '322-0', '330-1', '399-9'}
def is_osc(natureza_juridica: str) -> bool:
    if not natureza_juridica:
        return False
    # Simple heuristic: 3XX range = non-profits
    return natureza_juridica.strip().startswith('3')
```

CNPJ normalization:
```python
import re
def normalize_cnpj(raw: str) -> str:
    digits = re.sub(r'[^0-9]', '', str(raw))
    return digits.zfill(14) if digits and digits != '0' * 14 else ''
```
  </action>
  <verify>
Run `python -c "from src.loader.upsert import extract_proponentes_from_propostas; print('Import OK')"` and verify no import errors. Then run `python -c "from src.orchestrator.pipeline import run_pipeline; print('Pipeline import OK')"`.
  </verify>
  <done>Pipeline extracts proponentes from propostas CSV, normalizes CNPJs, classifies OSC/government, computes aggregations, and upserts to proponentes table. Running pipeline populates proponentes dimension table alongside existing entities.</done>
</task>

</tasks>

<verification>
1. `python -c "from src.loader.db_models import Base; print([t for t in Base.metadata.tables])"` includes "proponentes"
2. Import chain works: `python -c "from src.orchestrator.pipeline import run_pipeline; print('OK')"`
3. Proponente model has all required columns: cnpj, nome, natureza_juridica, is_osc, total_propostas, total_emendas, valor_total_emendas
</verification>

<success_criteria>
- Proponente SQLAlchemy model exists with CNPJ unique constraint and is_osc classification
- ETL pipeline extracts proponentes from propostas CSV with CNPJ deduplication
- Aggregation metrics (total_propostas, total_emendas, valor_total_emendas) are computed
- All imports pass without errors
</success_criteria>

<output>
After completion, create `.planning/phases/05-client-qualification/05-01-SUMMARY.md`
</output>
