---
phase: 04-data-dashboard
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/dashboard/streamlit_app.py
  - src/dashboard/config.py
  - src/dashboard/queries/metrics.py
  - src/dashboard/queries/entities.py
  - src/dashboard/queries/history.py
  - src/dashboard/components/metrics.py
  - src/dashboard/components/filters.py
  - src/dashboard/components/export.py
  - src/dashboard/pages/home.py
autonomous: true

must_haves:
  truths:
    - "Dashboard displays row counts per entity table (programas, propostas, apoiadores, emendas)"
    - "Dashboard shows data freshness (last extraction date and time)"
    - "Home page shows metric cards at top and recent data table at bottom without scrolling"
    - "Home page recent propostas table defaults to last 7 days based on extraction_date"
    - "Home page includes extraction history section showing pipeline run status"
  artifacts:
    - path: "src/dashboard/streamlit_app.py"
      provides: "Streamlit entrypoint with st.navigation and session_state initialization"
      min_lines: 30
    - path: "src/dashboard/config.py"
      provides: "Database connection via st.connection or SQLAlchemy engine"
      min_lines: 15
    - path: "src/dashboard/queries/metrics.py"
      provides: "Cached query functions for KPI metrics (row counts, freshness)"
      min_lines: 30
    - path: "src/dashboard/queries/entities.py"
      provides: "Cached query functions for entity data retrieval"
      min_lines: 40
    - path: "src/dashboard/queries/history.py"
      provides: "Cached query for extraction_logs history"
      min_lines: 20
    - path: "src/dashboard/components/metrics.py"
      provides: "Reusable KPI card rendering with st.metric"
      min_lines: 15
    - path: "src/dashboard/components/filters.py"
      provides: "Reusable filter widgets with session_state callbacks"
      min_lines: 20
    - path: "src/dashboard/components/export.py"
      provides: "CSV download button component"
      min_lines: 10
    - path: "src/dashboard/pages/home.py"
      provides: "Overview page with metric cards, recent propostas table (7-day default), and extraction history section"
      min_lines: 60
  key_links:
    - from: "src/dashboard/config.py"
      to: "PostgreSQL database"
      via: "SQLAlchemy engine from src.loader.database or st.connection"
      pattern: "get_engine|st\\.connection"
    - from: "src/dashboard/queries/metrics.py"
      to: "src/loader/db_models.py"
      via: "SQLAlchemy queries against ORM models"
      pattern: "Proposta|Programa|Apoiador|Emenda|ExtractionLog"
    - from: "src/dashboard/pages/home.py"
      to: "src/dashboard/queries/metrics.py"
      via: "Import and call cached query functions"
      pattern: "from.*queries.*import|get_.*count"
    - from: "src/dashboard/pages/home.py"
      to: "src/dashboard/queries/history.py"
      via: "Import get_extraction_history for pipeline run status section"
      pattern: "from.*queries.*history.*import|get_extraction_history"
---

<objective>
Build the Streamlit dashboard foundation: entrypoint with multipage navigation, database connection layer, cached query functions for all data needs, reusable UI components (metrics cards, filters, CSV export), and the home overview page with KPI cards, recent data table, and extraction history section.

Purpose: Establishes the complete infrastructure that all entity pages will build upon. The home page delivers immediate operational visibility with row counts, data freshness, recent propostas (default 7-day window), and pipeline run history.

Output: Working Streamlit app with sidebar navigation (5 tabs: Home + 4 entity types per locked decision), home page showing entity row counts + data freshness + recent propostas + extraction history, and all shared query/component infrastructure ready for entity pages.
</objective>

<execution_context>
@/Users/pauloloureiro/.claude/get-shit-done/workflows/execute-plan.md
@/Users/pauloloureiro/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-data-dashboard/04-CONTEXT.md
@.planning/phases/04-data-dashboard/04-RESEARCH.md
@src/loader/db_models.py
@src/loader/database.py
@src/config.py
@pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Streamlit foundation (entrypoint, config, query layer)</name>
  <files>
    src/dashboard/__init__.py
    src/dashboard/streamlit_app.py
    src/dashboard/config.py
    src/dashboard/queries/__init__.py
    src/dashboard/queries/metrics.py
    src/dashboard/queries/entities.py
    src/dashboard/queries/history.py
  </files>
  <action>
    1. Add `streamlit>=1.54.0` to pyproject.toml dependencies and run `uv sync`.

    2. Create `src/dashboard/__init__.py` (empty).

    3. Create `src/dashboard/config.py`:
       - Function `get_db_engine()` that reuses the existing `src.loader.database.get_engine()` to get the SQLAlchemy engine.
       - Function `run_query(query_str: str, params: dict = None) -> pd.DataFrame` that executes a SQL query via the engine and returns a pandas DataFrame. Use `@st.cache_data(ttl="10m")` for caching.
       - Import pandas. Do NOT use st.connection (the existing project uses env vars + SQLAlchemy, not Streamlit secrets). Reuse the existing database infrastructure from `src.loader.database`.

    4. Create `src/dashboard/queries/__init__.py` (empty).

    5. Create `src/dashboard/queries/metrics.py`:
       - `get_entity_counts() -> dict` â€” Returns {"programas": N, "propostas": N, "apoiadores": N, "emendas": N} by querying COUNT(*) from each table. Cached with `@st.cache_data(ttl="10m")`.
       - `get_data_freshness() -> dict` â€” Returns {"last_extraction": datetime, "hours_ago": float, "status": str} by querying the most recent ExtractionLog. Status is "fresh" (<25h), "stale" (<48h), or "critical" (>48h).

    6. Create `src/dashboard/queries/entities.py`:
       - `get_propostas(limit: int = 1000, filters: dict = None) -> pd.DataFrame` â€” Query propostas table with optional filters (estado, situacao, date range). Returns DataFrame.
       - `get_recent_propostas(days: int = 7) -> pd.DataFrame` â€” Query propostas WHERE extraction_date >= (today - days). This is specifically for the home page's default 7-day operational view per user decision. Returns DataFrame sorted by extraction_date DESC.
       - `get_programas(limit: int = 1000, filters: dict = None) -> pd.DataFrame` â€” Query programas table.
       - `get_apoiadores(limit: int = 1000, filters: dict = None) -> pd.DataFrame` â€” Query apoiadores table.
       - `get_emendas(limit: int = 1000, filters: dict = None) -> pd.DataFrame` â€” Query emendas table.
       - `get_related_entities(proposta_id: str) -> dict` â€” Given a proposta transfer_gov_id, return {"programas": df, "apoiadores": df, "emendas": df} by querying junction tables and joining.
       - All functions cached with `@st.cache_data(ttl="10m")`. All queries use SQL LIMIT to prevent large result sets blocking reruns.

    7. Create `src/dashboard/queries/history.py`:
       - `get_extraction_history(days: int = 30) -> pd.DataFrame` â€” Query extraction_logs for last N days, return DataFrame with columns: run_date, status, total_records, records_inserted, records_updated, duration_seconds, error_message.
       - Cached with `@st.cache_data(ttl="10m")`.

    8. Create `src/dashboard/streamlit_app.py`:
       - Initialize all `st.session_state` keys at the top: `selected_proposta_id` (None), `time_range_days` (7), `active_entity_filter` (None).
       - Use `st.navigation` with `st.Page` for sidebar navigation with exactly 5 tabs per locked decision: Home, Propostas, Programas, Apoiadores, Emendas. NO other tabs â€” extraction history is a section within the Home page, NOT a separate sidebar tab.
       - Set page config: `st.set_page_config(page_title="PROJETUS Dashboard", page_icon="ðŸ“Š", layout="wide")`.
       - For pages not yet created (propostas, programas, apoiadores, emendas), use placeholder pages that show "Coming soon" messages so the app runs without errors.

    Important: All query functions must handle the case where tables are empty gracefully (return empty DataFrames, not errors). Use `.copy()` on any cached DataFrame before mutation. Portuguese characters must render correctly â€” use UTF-8 throughout.
  </action>
  <verify>
    Run `cd /Users/pauloloureiro/Desktop/Work/Sigma/Projects/Projetus && uv run python -c "from src.dashboard.config import get_db_engine; from src.dashboard.queries.metrics import get_entity_counts; from src.dashboard.queries.entities import get_propostas, get_recent_propostas; from src.dashboard.queries.history import get_extraction_history; print('All imports OK')"` to verify all modules import correctly.
  </verify>
  <done>All query functions importable (including get_recent_propostas for 7-day default), streamlit_app.py has navigation with exactly 5 tabs (Home + 4 entity types per locked decision), config.py connects to existing database infrastructure, all __init__.py files created, streamlit added to dependencies.</done>
</task>

<task type="auto">
  <name>Task 2: Create shared UI components and home overview page with extraction history section</name>
  <files>
    src/dashboard/components/__init__.py
    src/dashboard/components/metrics.py
    src/dashboard/components/filters.py
    src/dashboard/components/export.py
    src/dashboard/pages/__init__.py
    src/dashboard/pages/home.py
  </files>
  <action>
    1. Create `src/dashboard/components/__init__.py` and `src/dashboard/pages/__init__.py` (empty).

    2. Create `src/dashboard/components/metrics.py`:
       - `render_metric_cards(counts: dict, freshness: dict)` â€” Renders a row of 4 st.metric cards (one per entity) using st.columns(4). Each card shows entity name and row count. Below the 4 cards, render a data freshness indicator using st.metric showing "Last Extraction" with the datetime and delta showing hours ago. Use color coding via st.metric's delta_color: "normal" for fresh, "off" for stale/critical.
       - Use st.metric which natively supports sparklines in Streamlit 1.54+ (pass historical data if available from extraction history).

    3. Create `src/dashboard/components/filters.py`:
       - `render_time_range_selector()` â€” Renders preset buttons (7 days, 14 days, 30 days) using st.segmented_control or st.radio horizontal. Updates `st.session_state.time_range_days`. Default is 7 days per user decision.
       - `render_entity_search(key: str) -> str` â€” Renders a text input for search filtering. Returns the search term. Key parameter ensures unique widget keys per page.
       - `render_column_filters(df: pd.DataFrame, columns: list, key_prefix: str) -> dict` â€” For specified columns, renders selectbox/multiselect filters. Returns dict of {column: selected_values}.

    4. Create `src/dashboard/components/export.py`:
       - `render_csv_export(df: pd.DataFrame, filename: str)` â€” Renders a st.download_button that exports the current filtered DataFrame as CSV. Use `df.to_csv(index=False).encode("utf-8")` for proper Portuguese character encoding.

    5. Create `src/dashboard/pages/home.py`:
       - This is the home/overview page function (called by st.navigation).
       - Layout per user decision: split view â€” top section with metric cards, bottom section with main data table, both visible without scrolling.
       - Page title: "PROJETUS - Transfer Gov Dashboard" or similar.

       **Top section:**
       - Call `render_metric_cards()` with data from `get_entity_counts()` and `get_data_freshness()`.

       **Middle section â€” Recent Propostas table:**
       - Add a time range selector for operational data using `render_time_range_selector()`.
       - Show a st.dataframe of recent propostas using `get_recent_propostas(days=st.session_state.time_range_days)`. CRITICAL per user decision: the default time range is 7 days for operational data. The query MUST filter WHERE extraction_date >= (today - selected_days). When the user changes the time range selector, the table updates accordingly.
       - Use built-in search/sort/filter via `st.dataframe` column_config.

       **Bottom section â€” Extraction History (operational visibility):**
       - Render an "Extraction History" section (using st.subheader or st.expander) WITHIN the home page â€” this is NOT a separate sidebar tab per locked decision (sidebar has only Home + 4 entity types).
       - Show extraction_logs data from `get_extraction_history(days=st.session_state.time_range_days)` (respects the same time range selector, default 7 days view, up to 30 days available).
       - Summary row: Total runs in period, success count, partial count, failed count using st.metric cards in columns.
       - History table: st.dataframe showing all runs with columns: run_date (formatted DD/MM/YYYY HH:MM), status (with color-coded badges â€” green for success, yellow for partial, red for failed), total_records, records_inserted, records_updated, duration_seconds (formatted as "Xs" or "Xm Ys").
       - Sort by run_date descending (most recent first).
       - If error_message exists for a run, show it in an expandable row or via row selection detail.
       - CSV export for extraction history data.
       - Handle empty extraction_logs table (show "No extraction history available" message).

    Important: Use `st.session_state` for all filter state. Initialize any new state keys with defaults at the top of the page function (check `if key not in st.session_state` before setting). All DataFrames from cache must be `.copy()`ed before display/mutation. Format dates in Brazilian format (DD/MM/YYYY HH:MM) for display. Status values from ExtractionLog are: 'success', 'partial', 'failed'.
  </action>
  <verify>
    Run `cd /Users/pauloloureiro/Desktop/Work/Sigma/Projects/Projetus && uv run streamlit run src/dashboard/streamlit_app.py --server.headless true --server.port 8501 &` then wait 5 seconds, then `curl -s http://localhost:8501 | head -20` to verify Streamlit starts. Then kill the process. If database is not available, verify at minimum that the app starts without crashing by checking the curl response contains "Streamlit" or HTML content.
  </verify>
  <done>Home page renders with: (1) metric cards (row counts per entity + data freshness) at top, (2) recent propostas table filtered to last 7 days by default via WHERE extraction_date >= (today - 7) with time range selector, (3) extraction history section showing pipeline runs with color-coded status, run counts, and duration. Sidebar shows exactly 5 navigation tabs (Home, Propostas, Programas, Apoiadores, Emendas) per locked decision. Shared components (metrics, filters, export) are importable and reusable. CSV export works with UTF-8 encoding for Portuguese characters.</done>
</task>

</tasks>

<verification>
1. `uv run python -c "import src.dashboard.streamlit_app"` succeeds
2. All query modules import without error
3. All component modules import without error
4. Streamlit app starts on port 8501 without crashing
5. Home page is the default page with metric cards, recent propostas (7-day default), and extraction history section
6. Sidebar navigation shows exactly 5 tabs: Home, Propostas, Programas, Apoiadores, Emendas (no Extraction History tab)
</verification>

<success_criteria>
- Streamlit app runs and shows sidebar with exactly 5 navigation tabs (Home, Propostas, Programas, Apoiadores, Emendas) per locked decision
- Home page displays entity row counts as metric cards
- Home page displays data freshness indicator
- Home page displays recent propostas filtered to last 7 days by default (WHERE extraction_date >= today - 7)
- Home page includes extraction history section with pipeline run status, row counts, duration
- Time range selector updates both recent propostas table and extraction history section
- Query layer connects to existing PostgreSQL via src.loader.database
- All cached queries use TTL of 10 minutes
- CSV export component handles UTF-8/Portuguese correctly
</success_criteria>

<output>
After completion, create `.planning/phases/04-data-dashboard/04-01-SUMMARY.md`
</output>
