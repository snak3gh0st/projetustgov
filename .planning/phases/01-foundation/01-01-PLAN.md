---
phase: 01-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - src/__init__.py
  - src/config.py
  - src/monitor/logger.py
  - src/monitor/__init__.py
  - src/main.py
  - .env.example
  - .gitignore
  - docker-compose.yml
  - Dockerfile
autonomous: true

must_haves:
  truths:
    - "Running `uv sync` installs all project dependencies without errors"
    - "All project directories exist with correct structure matching RESEARCH.md architecture"
    - "Settings load from .env file with validation (missing required vars raise clear errors)"
    - "Loguru produces JSON-formatted log files and human-readable console output"
    - "docker-compose up starts PostgreSQL accessible on localhost:5432"
  artifacts:
    - path: "pyproject.toml"
      provides: "Project definition with all dependencies"
      contains: "playwright"
    - path: "src/config.py"
      provides: "Pydantic BaseSettings configuration"
      contains: "class Settings"
    - path: "src/monitor/logger.py"
      provides: "Loguru configuration for JSON + console logging"
      contains: "serialize=True"
    - path: "docker-compose.yml"
      provides: "PostgreSQL service for local development"
      contains: "postgres"
    - path: ".env.example"
      provides: "Template for required environment variables"
      contains: "DATABASE_URL"
  key_links:
    - from: "src/config.py"
      to: ".env"
      via: "Pydantic BaseSettings env_file loading"
      pattern: 'env_file.*\.env'
    - from: "src/monitor/logger.py"
      to: "logs/"
      via: "Loguru file sink with rotation"
      pattern: "logger\\.add.*logs/"
---

<objective>
Bootstrap the Projetus project: initialize Python project with uv, install all dependencies, create directory structure, configure settings management via Pydantic BaseSettings, set up Loguru structured logging, and provide docker-compose for local PostgreSQL.

Purpose: Every subsequent plan depends on the project existing with dependencies installed, config loading, and logging working. This is the foundation all other plans build on.
Output: Working Python project with `uv sync` passing, config loading from .env, structured logging active, and PostgreSQL available via docker-compose.
</objective>

<execution_context>
@/Users/pauloloureiro/.claude/get-shit-done/workflows/execute-plan.md
@/Users/pauloloureiro/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-CONTEXT.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Initialize project with uv, install dependencies, create directory structure</name>
  <files>
    pyproject.toml
    src/__init__.py
    src/crawler/__init__.py
    src/parser/__init__.py
    src/transformer/__init__.py
    src/loader/__init__.py
    src/orchestrator/__init__.py
    src/monitor/__init__.py
    .gitignore
  </files>
  <action>
    Initialize the Python project using uv:
    1. Run `uv init --name projetus --python 3.11` in the project root (if pyproject.toml doesn't exist yet). If the project root already has files, create pyproject.toml manually with `[project]` section: name="projetus", requires-python=">=3.11".
    2. Add core dependencies via uv:
       ```
       uv add playwright polars sqlalchemy "psycopg[binary]" pydantic pydantic-settings loguru tenacity apscheduler fastapi openpyxl charset-normalizer python-dotenv httpx uvicorn
       ```
    3. Add dev dependencies:
       ```
       uv add --dev pytest pytest-asyncio ruff mypy
       ```
    4. Run `uv run playwright install chromium` to install the Playwright browser.
    5. Create all package directories with __init__.py files:
       - src/
       - src/crawler/
       - src/parser/
       - src/transformer/
       - src/loader/
       - src/orchestrator/
       - src/monitor/
       - tests/
       - tests/fixtures/
       - data/raw/ (for downloaded files)
       - logs/ (for log output)
    6. Create .gitignore with entries for: .env, __pycache__/, *.pyc, .venv/, data/raw/*, logs/*, .mypy_cache/, .ruff_cache/, !data/raw/.gitkeep, !logs/.gitkeep. Add .gitkeep files in data/raw/ and logs/ so directories are tracked.

    IMPORTANT: Use `uv` (not pip or venv). The project uses uv as the package manager per RESEARCH.md.
    IMPORTANT: Do NOT use `uv init` if pyproject.toml already exists from a prior partial run -- just add dependencies.
  </action>
  <verify>
    Run `uv sync` -- should complete without errors.
    Run `uv run python -c "import playwright; import polars; import sqlalchemy; import pydantic; import loguru; import tenacity; import apscheduler; import fastapi; import httpx; print('All imports OK')"` -- should print "All imports OK".
    Verify directory structure exists: `ls src/crawler src/parser src/transformer src/loader src/orchestrator src/monitor tests/fixtures data/raw logs`.
  </verify>
  <done>All dependencies installed, all directories created, `uv sync` passes, all core imports succeed.</done>
</task>

<task type="auto">
  <name>Task 2: Create config, logging, docker-compose, and entry point skeleton</name>
  <files>
    src/config.py
    src/monitor/logger.py
    src/main.py
    .env.example
    docker-compose.yml
    Dockerfile
  </files>
  <action>
    1. Create `src/config.py` with Pydantic BaseSettings class `Settings`:
       - database_url: str (required, e.g., "postgresql+psycopg://projetus:projetus@localhost:5432/projetus")
       - transfer_gov_url: str (default: "https://dd-publico.serpro.gov.br/extensions/gestao-transferencias/gestao-transferencias.html")
       - telegram_bot_token: str (required)
       - telegram_chat_id: str (required)
       - extraction_hour: int (default: 9)
       - extraction_minute: int (default: 15)
       - max_retries: int (default: 3)
       - retry_base_delay: int (default: 2)
       - health_port: int (default: 8080)
       - raw_data_dir: str (default: "data/raw")
       - raw_retention_days: int (default: 30)
       - model_config with env_file=".env", env_file_encoding="utf-8"
       Add a module-level function `get_settings() -> Settings` that caches the singleton.

    2. Create `src/monitor/logger.py` with `configure_logging()` function:
       - Remove default Loguru handler
       - Add stderr handler: human-readable format with colorize=True, level=INFO
       - Add file handler: "logs/projetus_{time:YYYY-MM-DD}.log", serialize=True (JSON), rotation="500 MB", retention="30 days", compression="zip", level=DEBUG, diagnose=False
       Follow the exact pattern from RESEARCH.md code examples.

    3. Create `src/main.py` as the entry point skeleton:
       - Import configure_logging and call it
       - Import get_settings and log that config loaded
       - Add `if __name__ == "__main__":` block that logs "Projetus starting..." (placeholder for scheduler + health endpoint from Plan 06)

    4. Create `.env.example` with all required environment variables as comments:
       ```
       DATABASE_URL=postgresql+psycopg://projetus:projetus@localhost:5432/projetus
       TELEGRAM_BOT_TOKEN=your-telegram-bot-token
       TELEGRAM_CHAT_ID=your-telegram-chat-id
       ```

    5. Create `docker-compose.yml` with PostgreSQL 15 service:
       - Service name: db
       - Image: postgres:15
       - Environment: POSTGRES_USER=projetus, POSTGRES_PASSWORD=projetus, POSTGRES_DB=projetus
       - Ports: 5432:5432
       - Volume: pgdata:/var/lib/postgresql/data
       - Named volume: pgdata

    6. Create `Dockerfile` for the application:
       - FROM python:3.11-slim
       - Install uv via pip
       - COPY pyproject.toml uv.lock ./
       - RUN uv sync --frozen
       - RUN uv run playwright install --with-deps chromium
       - COPY src/ ./src/
       - CMD ["uv", "run", "python", "-m", "src.main"]

    IMPORTANT: Use pydantic_settings (not pydantic) for BaseSettings import -- it's a separate package since Pydantic v2.
  </action>
  <verify>
    1. Copy .env.example to .env: `cp .env.example .env`
    2. Run `uv run python -c "from src.config import get_settings; s = get_settings(); print(f'DB: {s.database_url}')"` -- should print the database URL from .env.
    3. Run `uv run python -c "from src.monitor.logger import configure_logging; configure_logging(); from loguru import logger; logger.info('test')"` -- should produce console output AND create a log file in logs/.
    4. Run `docker compose up -d db` -- PostgreSQL should start. Verify with `docker compose exec db pg_isready` (should return "accepting connections").
    5. Run `docker compose down` to clean up.
  </verify>
  <done>Config loads from .env with validation, Loguru writes JSON logs to file and readable logs to console, PostgreSQL starts via docker-compose and accepts connections, Dockerfile exists for containerized deployment.</done>
</task>

</tasks>

<verification>
1. `uv sync` completes without errors
2. All Python imports succeed (playwright, polars, sqlalchemy, pydantic, loguru, tenacity, apscheduler, fastapi, httpx)
3. `from src.config import get_settings` loads settings from .env
4. Loguru writes structured JSON logs to logs/ directory
5. `docker compose up -d db && docker compose exec db pg_isready` shows PostgreSQL accepting connections
6. Directory structure matches RESEARCH.md architecture (src/crawler/, src/parser/, etc.)
</verification>

<success_criteria>
- Project initialized with uv and all 16+ dependencies installed
- Config module validates and loads environment variables
- Logging produces both human-readable console and machine-parseable JSON file output
- PostgreSQL available via docker-compose for local development
- All subsequent plans can import from src.config and src.monitor.logger
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-01-SUMMARY.md`
</output>
